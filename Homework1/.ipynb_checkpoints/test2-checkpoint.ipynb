{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_Te27fi-0pP"
   },
   "source": [
    "# **HW1: Regression**\n",
    "In *assignment 1*, you need to finish:\n",
    "\n",
    "1.  Basic Part: Implement two regression models to predict the Systolic blood pressure (SBP) of a patient. You will need to implement **both Matrix Inversion and Gradient Descent**.\n",
    "\n",
    "\n",
    "> *   Step 1: Split Data\n",
    "> *   Step 2: Preprocess Data\n",
    "> *   Step 3: Implement Regression\n",
    "> *   Step 4: Make Prediction\n",
    "> *   Step 5: Train Model and Generate Result\n",
    "\n",
    "2.  Advanced Part: Implement one regression model to predict the SBP of multiple patients in a different way than the basic part. You can choose **either** of the two methods for this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wDdnos-4uUv"
   },
   "source": [
    "# **1. Basic Part (55%)**\n",
    "In the first part, you need to implement the regression to predict SBP from the given DBP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_EVqWlB-DTF"
   },
   "source": [
    "## 1.1 Matrix Inversion Method (25%)\n",
    "\n",
    "\n",
    "*   Save the prediction result in a csv file **hw1_basic_mi.csv**\n",
    "*   Print your coefficient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzCR7vk9BFkf"
   },
   "source": [
    "### *Import Packages*\n",
    "\n",
    "> Note: You **cannot** import any other package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HL5XjqFf4wSj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnWjrzi0dMPz"
   },
   "source": [
    "### *Global attributes*\n",
    "Define the global attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWLDPOlHBbcK"
   },
   "outputs": [],
   "source": [
    "training_dataroot = 'hw1_basic_training.csv' # Training data file file named as 'hw1_basic_training.csv'\n",
    "testing_dataroot = 'hw1_basic_testing.csv'   # Testing data file named as 'hw1_basic_training.csv'\n",
    "output_dataroot = 'hw1_basic_mi.csv' # Output file will be named as 'hw1_basic.csv'\n",
    "\n",
    "training_datalist =  [] # Training datalist, saved as numpy array\n",
    "testing_datalist =  [] # Testing datalist, saved as numpy array\n",
    "\n",
    "output_datalist =  [] # Your prediction, should be 20 * 1 matrix and saved as numpy array\n",
    "                      # The format of each row should be ['sbp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsFC-cvqIcYK"
   },
   "source": [
    "You can add your own global attributes here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OUbS2BEgcut6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUoRFoQjBW5S"
   },
   "source": [
    "### *Load the Input File*\n",
    "First, load the basic input file **hw1_basic_training.csv** and **hw1_basic_testing.csv**\n",
    "\n",
    "Input data would be stored in *training_datalist* and *testing_datalist*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dekR1KnqBtI6"
   },
   "outputs": [],
   "source": [
    "# Read input csv to datalist\n",
    "with open(training_dataroot, newline='') as csvfile:\n",
    "  training_datalist = np.array(list(csv.reader(csvfile)))\n",
    "\n",
    "with open(testing_dataroot, newline='') as csvfile:\n",
    "  testing_datalist = np.array(list(csv.reader(csvfile)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kYPuikLCFx4"
   },
   "source": [
    "### *Implement the Regression Model*\n",
    "\n",
    "> Note: It is recommended to use the functions we defined, you can also define your own functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWwdx06JNEYs"
   },
   "source": [
    "#### Step 1: Split Data\n",
    "Split data in *training_datalist* into training dataset and validation dataset\n",
    "* Validation dataset is used to validate your own model without the testing data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "USDciENcB-5F"
   },
   "outputs": [],
   "source": [
    "def SplitData():\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-3Qln4aNgVy"
   },
   "source": [
    "#### Step 2: Preprocess Data\n",
    "Handle the unreasonable data\n",
    "> Hint: Outlier and missing data can be handled by removing the data or adding the values with the help of statistics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XXvW1n_5NkQ5"
   },
   "outputs": [],
   "source": [
    "def PreprocessData():\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDLpJmQUN3V6"
   },
   "source": [
    "#### Step 3: Implement Regression\n",
    "> use Matrix Inversion to finish this part\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tx9n1_23N8C0"
   },
   "outputs": [],
   "source": [
    "def MatrixInversion():\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NxRNFwyN8xd"
   },
   "source": [
    "#### Step 4: Make Prediction\n",
    "Make prediction of testing dataset and store the value in *output_datalist*\n",
    "The final *output_datalist* should look something like this \n",
    "> [ [100], [80], ... , [90] ] where each row contains the predicted SBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EKlDIC2-N_lk"
   },
   "outputs": [],
   "source": [
    "def MakePrediction():\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCd0Z6izOCwq"
   },
   "source": [
    "#### Step 5: Train Model and Generate Result\n",
    "\n",
    "> Notice: **Remember to output the coefficients of the model here**, otherwise 5 points would be deducted\n",
    "* If your regression model is *3x^2 + 2x^1 + 1*, your output would be:\n",
    "```\n",
    "3 2 1\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iCL92EPKOFIn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8Jhd8wAOk3D"
   },
   "source": [
    "### *Write the Output File*\n",
    "Write the prediction to output csv\n",
    "> Format: 'sbp'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYQVYLlKOtDB"
   },
   "outputs": [],
   "source": [
    "with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
    "  writer = csv.writer(csvfile)\n",
    "  for row in output_datalist:\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1J3WOhglA9ML"
   },
   "source": [
    "## 1.2 Gradient Descent Method (30%)\n",
    "\n",
    "\n",
    "*   Save the prediction result in a csv file **hw1_basic_gd.csv**\n",
    "*   Output your coefficient update in a csv file **hw1_basic_coefficient.csv**\n",
    "*   Print your coefficient\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkMqa_xjXhEv"
   },
   "source": [
    "### *Global attributes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wNZtRWUeXpEu"
   },
   "outputs": [],
   "source": [
    "output_dataroot = 'hw1_basic_gd.csv' # Output file will be named as 'hw1_basic.csv'\n",
    "coefficient_output_dataroot = 'hw1_basic_coefficient.csv'\n",
    "\n",
    "training_datalist =  [] # Training datalist, saved as numpy array\n",
    "testing_datalist =  [] # Testing datalist, saved as numpy array\n",
    "\n",
    "output_datalist =  [] # Your prediction, should be 20 * 1 matrix and saved as numpy array\n",
    "                      # The format of each row should be ['sbp']\n",
    "\n",
    "coefficient_output = [] # Your coefficient update during gradient descent\n",
    "                   # Should be a (number of iterations * number_of coefficient) matrix\n",
    "                   # The format of each row should be ['w0', 'w1', ...., 'wn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5DeHxdLdai3"
   },
   "source": [
    "Your own global attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2IO5tYSdaFd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVBLT1aqXuW0"
   },
   "source": [
    "### *Implement the Regression Model*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecPWpcOnXhCZ"
   },
   "source": [
    "#### Step 1: Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PEf_qGvYHu0"
   },
   "outputs": [],
   "source": [
    "def SplitData():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpSoPDPKX56w"
   },
   "source": [
    "#### Step 2: Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLTXOWRwYHiS"
   },
   "outputs": [],
   "source": [
    "def PreprocessData():\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TV_y82gXX6a-"
   },
   "source": [
    "#### Step 3: Implement Regression\n",
    "> use Gradient Descent to finish this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-635Ee00YHTE"
   },
   "outputs": [],
   "source": [
    "def GradientDescent():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLuPxs2ZX21S"
   },
   "source": [
    "#### Step 4: Make Prediction\n",
    "\n",
    "Make prediction of testing dataset and store the values in *output_datalist*\n",
    "The final *output_datalist* should look something like this \n",
    "> [ [100], [80], ... , [90] ] where each row contains the predicted SBP\n",
    "\n",
    "Remember to also store your coefficient update in *coefficient_output*\n",
    "The final *coefficient_output* should look something like this\n",
    "> [ [1, 0, 3, 5], ... , [0.1, 0.3, 0.2, 0.5] ] where each row contains the [w0, w1, ..., wn] of your coefficient\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8pnNDlQeYGtE"
   },
   "outputs": [],
   "source": [
    "def MakePrediction():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IScbxxMAYAgZ"
   },
   "source": [
    "#### Step 5: Train Model and Generate Result\n",
    "\n",
    "> Notice: **Remember to output the coefficients of the model here**, otherwise 5 points would be deducted\n",
    "* If your regression model is *3x^2 + 2x^1 + 1*, your output would be:\n",
    "```\n",
    "3 2 1\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90EisOc7YG-N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1DpV_HcYFpl"
   },
   "source": [
    "### *Write the Output File*\n",
    "\n",
    "Write the prediction to output csv\n",
    "> Format: 'sbp'\n",
    "\n",
    "**Write the coefficient update to csv**\n",
    "> Format: 'w0', 'w1', ..., 'wn'\n",
    ">*   The number of columns is based on your number of coefficient\n",
    ">*   The number of row is based on your number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NLSHgpDvDXNI"
   },
   "outputs": [],
   "source": [
    "with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
    "  writer = csv.writer(csvfile)\n",
    "  for row in output_datalist:\n",
    "    writer.writerow(row)\n",
    "\n",
    "with open(coefficient_output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
    "  writer = csv.writer(csvfile)\n",
    "  for row in coefficient_output:\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rx4408qg4xMQ"
   },
   "source": [
    "# **2. Advanced Part (40%)**\n",
    "In the second part, you need to implement the regression in a different way than the basic part to help your predictions of multiple patients SBP.\n",
    "\n",
    "You can choose **either** Matrix Inversion or Gradient Descent method.\n",
    "\n",
    "The training data will be in **hw1_advanced_training.csv** and the testing data will be in **hw1_advanced_testing.csv**.\n",
    "\n",
    "Output your prediction in **hw1_advanced.csv**\n",
    "\n",
    "Notice:\n",
    "> You cannot import any other package other than those given\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input the training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "v66HUClZcxaE"
   },
   "outputs": [],
   "source": [
    "training_dataroot = 'hw1_advanced_training.csv' # Training data file file named as 'hw1_basic_training.csv'\n",
    "testing_dataroot = 'hw1_advanced_testing.csv'   # Testing data file named as 'hw1_basic_training.csv'\n",
    "output_dataroot = 'hw1_advanced.csv' # Output file will be named as 'hw1_basic.csv'\n",
    "\n",
    "training_datalist =  [] # Training datalist, saved as numpy array\n",
    "testing_datalist =  [] # Testing datalist, saved as numpy array\n",
    "\n",
    "output_datalist =  [] # Your prediction, should be 220 * 1 matrix and saved as numpy array\n",
    "                      # The format of each row should be ['sbp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 data before\n",
      "Polynomial order 1\n",
      "Filter data using Z value 4 \n",
      "\n",
      "BEFORE = 5696\n",
      "AFTER DROP NAN = 5436\n",
      "AFTER Z VALUE = 5328\n",
      "============================================\n",
      " === FINISH ===\n"
     ]
    }
   ],
   "source": [
    "uni_k = 5\n",
    "order = 1\n",
    "z_max = 4\n",
    "iterations = 1000\n",
    "learning_rate = []\n",
    "\n",
    "print(\"Using\", uni_k, \"data before\")\n",
    "print(\"Polynomial order\", order)\n",
    "print(\"Filter data using Z value\", z_max, \"\\n\")\n",
    "\n",
    "# filter data function\n",
    "def cutData(data):\n",
    "    data = data.drop([\"charttime\"], axis=1)\n",
    "    return data.to_numpy()\n",
    "\n",
    "def makeLearningRate():\n",
    "    c = 0.000001\n",
    "    learning_rate.clear()\n",
    "    learning_rate.append(0.01)\n",
    "    for i in range(4):\n",
    "        for j in range(order):\n",
    "            learning_rate.append(0.1 * (c ** (j+1)))\n",
    "    for i in range(uni_k):\n",
    "        learning_rate.append(c)\n",
    "\n",
    "def MakeBatch(data, split):\n",
    "    batch = round(len(data) / split)\n",
    "    ret = []\n",
    "    \n",
    "    for i in range(split):\n",
    "        bot = i * batch\n",
    "        top = (i+1) * batch\n",
    "        if i == split-1:\n",
    "            top = len(data)\n",
    "        ret.append(data[bot:top])\n",
    "        \n",
    "    return ret\n",
    "\n",
    "def FilterData(data):\n",
    "    ret_data = dict()\n",
    "    \n",
    "    print(\"BEFORE =\", len(data))\n",
    "    data['temperature'].fillna(round(data['temperature'].mean(), 2), inplace = True)\n",
    "    data = data.dropna()\n",
    "    print(\"AFTER DROP NAN =\", len(data))\n",
    "    \n",
    "    topic = [\"temperature\", \"heartrate\", \"resprate\", \"o2sat\", \"sbp\"]\n",
    "    gd_mean = data[topic].mean()\n",
    "    gd_std = data[topic].std()\n",
    "    \n",
    "    for i in topic:\n",
    "        data = data[abs(data[i] - gd_mean[i]) / gd_std[i] <= z_max]\n",
    "    print(\"AFTER Z VALUE =\", len(data))\n",
    "    print(\"============================================\")\n",
    "        \n",
    "    \n",
    "    data = data.groupby(\"subject_id\")\n",
    "    for group_name, group_data in data:\n",
    "        group_data = group_data.drop([\"subject_id\", \"charttime\"], axis = 1)\n",
    "        ret_data[group_name] = group_data.to_numpy()\n",
    "#         print(\"SUBJECT\", group_name, \"=====\")\n",
    "#         for i in topic:\n",
    "#             print(i, \"===\")\n",
    "#             print(group_data[i].min())\n",
    "#             print(group_data[i].mean())\n",
    "#             print(group_data[i].max())\n",
    "        \n",
    "    return ret_data\n",
    "\n",
    "# split data function\n",
    "def Split_Data(data, num):\n",
    "    size = len(data)\n",
    "    split_size = round(size * num)\n",
    "    data1 = np.array(data[1:split_size]).astype('float64') # since index 0 is string\n",
    "    data2 = np.array(data[split_size:size]).astype('float64')\n",
    "    return data1, data2\n",
    "\n",
    "# training function\n",
    "def modif_x(data, k, x):\n",
    "    ret = [1]\n",
    "    n1 = len(data)\n",
    "    n2 = len(data[0])\n",
    "\n",
    "    for i in range(4):\n",
    "        for j in range(order):\n",
    "            ret.append(x[i] ** (j+1))\n",
    "    for i in range(k):\n",
    "        ret.append(data[n1-1-i][n2-1])\n",
    "        \n",
    "    return ret\n",
    "    \n",
    "def make_matrix(data, k):\n",
    "    new_data = []\n",
    "    for i in range(k, len(data)):\n",
    "        new_data.append([1])\n",
    "\n",
    "        for j in range(4):\n",
    "            for p in range(order):\n",
    "                new_data[i-k].append(data[i][j] ** (p+1))\n",
    "        for j in range(k):\n",
    "            new_data[i-k].append(data[i-1-j][4])\n",
    "        new_data[i-k].append(data[i][4])\n",
    "    \n",
    "    new_data = np.array(new_data)\n",
    "    return new_data\n",
    "\n",
    "def gradient_descent(data, weight):\n",
    "    n = len(weight)\n",
    "    w_new = np.zeros(n)\n",
    "    norm = -2/len(data)\n",
    "    \n",
    "    for row in data:\n",
    "        predict = 0\n",
    "        y = row[n]\n",
    "        for i in range(n):\n",
    "            predict += row[i] * weight[i]\n",
    "        for i in range(n):\n",
    "            w_new[i] += (norm) * (y - predict) * row[i]\n",
    "            \n",
    "    for i in range(n):\n",
    "        w_new[i] = weight[i] - learning_rate[i] * w_new[i]\n",
    "    return w_new\n",
    "        \n",
    "\n",
    "def matrix_inversion(data):\n",
    "    n = len(data[0])\n",
    "    X = np.array(data[:,0:n-1])\n",
    "    Y = np.array(data[:,n-1])\n",
    "\n",
    "    ret = np.linalg.inv(X.T @ X) @ X.T @ Y\n",
    "    return ret\n",
    "\n",
    "def train_func(data):\n",
    "    n = len(data[0])\n",
    "    grad = np.zeros(n-1)\n",
    "    #data = MakeBatch(data, 10)\n",
    "    #for batch in data:\n",
    "    for i in range(iterations):\n",
    "        grad = gradient_descent(data, grad)\n",
    "    #grad = matrix_inversion(data)\n",
    "    return grad\n",
    "\n",
    "def doPrediction(b, X):\n",
    "    ret = 0\n",
    "    for i in range(len(X)):\n",
    "        ret += b[i] * X[i]\n",
    "    return ret\n",
    "    \n",
    "# read files\n",
    "adv_training_data = pd.read_csv(training_dataroot)\n",
    "adv_testing_data = pd.read_csv(testing_dataroot)\n",
    "makeLearningRate()\n",
    "\n",
    "# data = FilterData(adv_training_data)\n",
    "\n",
    "# train every data\n",
    "def test_MAPE():\n",
    "    grad = dict()\n",
    "    mape = 0\n",
    "    for idx in data:\n",
    "        # for caluclating MAPE\n",
    "        train_data, test_data = Split_Data(data[idx], 0.9)\n",
    "        train_data = make_matrix(train_data, uni_k)\n",
    "        grad[idx] = train_func(train_data)\n",
    "        \n",
    "        msum = 0\n",
    "        for row in test_data:\n",
    "            X = modif_x(train_data, uni_k, row[0:4])\n",
    "            Y = doPrediction(grad[idx], X)\n",
    "            msum += abs(row[4] - Y) / row[4]\n",
    "            \n",
    "            X.append(Y)\n",
    "            X = np.array(X)\n",
    "            train_data = np.vstack((train_data, X))\n",
    "        mape = 100 / len(test_data) * msum\n",
    "        print(mape)\n",
    "    #print(mape/11, \"%\")\n",
    "\n",
    "def final():\n",
    "    grad = dict()\n",
    "    train_data = FilterData(adv_training_data)\n",
    "    test_data = cutData(adv_testing_data)\n",
    "    \n",
    "    for topic in train_data:\n",
    "        train_data[topic] = make_matrix(train_data[topic], uni_k)\n",
    "        grad[topic] = train_func(train_data[topic])\n",
    "    \n",
    "    for row in test_data:\n",
    "        sub_id = row[0]\n",
    "        X = row[1:5]\n",
    "        X = modif_x(train_data[sub_id], uni_k, X)\n",
    "        row[5] = doPrediction(grad[sub_id], X)\n",
    "        \n",
    "        X.append(row[5])\n",
    "        X = np.array(X)\n",
    "        train_data[sub_id] = np.vstack((train_data[sub_id], X))\n",
    "    \n",
    "    return test_data\n",
    "\n",
    "makeLearningRate()\n",
    "\n",
    "print(\"UNI_K = \", uni_k)\n",
    "test_MAPE()\n",
    "print()\n",
    "\n",
    "# out = final()\n",
    "# output_datalist = []\n",
    "\n",
    "# for row in out:\n",
    "#     output_datalist.append([row[5]])\n",
    "\n",
    "# print(\" === FINISH ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output your Prediction\n",
    "\n",
    "> your filename should be **hw1_advanced.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[138.16051185061664]\n",
      "[136.41031755649922]\n",
      "[139.39119575108776]\n",
      "[139.7411636004514]\n",
      "[140.64602106343008]\n",
      "[141.82817813748477]\n",
      "[142.3672038789362]\n",
      "[143.69560549407203]\n",
      "[143.92100712008394]\n",
      "[145.20329185924228]\n",
      "[145.76569550375714]\n",
      "[146.17519235046785]\n",
      "[147.01576184839996]\n",
      "[147.64754590890885]\n",
      "[147.8256394108033]\n",
      "[148.014561817419]\n",
      "[148.8441045616383]\n",
      "[149.26419218696353]\n",
      "[148.9719025163484]\n",
      "[149.43048362296298]\n",
      "[150.54793705180563]\n",
      "[149.98147813965082]\n",
      "[147.15486401657145]\n",
      "[146.55194656044696]\n",
      "[147.23125579263197]\n",
      "[145.85263646568964]\n",
      "[145.4556945992056]\n",
      "[144.4172653597532]\n",
      "[144.23200017109187]\n",
      "[143.28423098330603]\n",
      "[142.9411923943421]\n",
      "[142.46727610099273]\n",
      "[141.8091432212671]\n",
      "[141.44472196705522]\n",
      "[142.10891206213017]\n",
      "[141.28731639860158]\n",
      "[140.8697416089043]\n",
      "[140.4182668664029]\n",
      "[140.91884213456032]\n",
      "[140.17744469622858]\n",
      "[122.75753185455687]\n",
      "[122.27643328353453]\n",
      "[123.13378064948809]\n",
      "[124.11276398846334]\n",
      "[122.59083801287639]\n",
      "[121.5738165524446]\n",
      "[121.31691934292252]\n",
      "[120.90699073042921]\n",
      "[120.74219308940646]\n",
      "[120.04194157998388]\n",
      "[120.24017329260779]\n",
      "[119.96548837047379]\n",
      "[119.95200399240622]\n",
      "[119.79632640136894]\n",
      "[119.73657885682343]\n",
      "[119.5074067590595]\n",
      "[119.48113560718603]\n",
      "[119.15967632813278]\n",
      "[118.69005259776078]\n",
      "[118.68544696908415]\n",
      "[140.23473468560732]\n",
      "[139.97493962407586]\n",
      "[139.1566905435937]\n",
      "[138.66137476888363]\n",
      "[137.05477925682726]\n",
      "[137.98011870620422]\n",
      "[137.7838363743548]\n",
      "[137.3772379591307]\n",
      "[137.0884193384136]\n",
      "[136.88821352507483]\n",
      "[136.7751938139651]\n",
      "[136.6265900831026]\n",
      "[136.57451891542152]\n",
      "[136.35010405161168]\n",
      "[136.18137066896526]\n",
      "[136.0822139911867]\n",
      "[135.95001079185832]\n",
      "[135.83801863885884]\n",
      "[135.77047967157011]\n",
      "[135.72534054321204]\n",
      "[124.40968882109526]\n",
      "[124.84586565730454]\n",
      "[123.20008129379735]\n",
      "[125.1367019467622]\n",
      "[122.18486518901115]\n",
      "[123.95939641993479]\n",
      "[124.21580333611426]\n",
      "[124.18549538126271]\n",
      "[124.12560675014927]\n",
      "[123.81583526053078]\n",
      "[124.30696644034678]\n",
      "[124.40474254362199]\n",
      "[124.40430593833088]\n",
      "[124.27547981340958]\n",
      "[124.40840606815041]\n",
      "[124.22990904725137]\n",
      "[124.31613207048896]\n",
      "[124.47666034406868]\n",
      "[124.6705505576943]\n",
      "[124.68675407998973]\n",
      "[134.15460875328125]\n",
      "[132.99835370666688]\n",
      "[131.44775902896274]\n",
      "[131.8525786857412]\n",
      "[131.30786265020112]\n",
      "[132.00349979747395]\n",
      "[132.08151037068166]\n",
      "[131.7262230234143]\n",
      "[131.45249855588312]\n",
      "[131.3845173926714]\n",
      "[132.14692347466783]\n",
      "[131.54328515153853]\n",
      "[131.37251741988194]\n",
      "[131.40222417210686]\n",
      "[131.51767595406315]\n",
      "[131.57613636915622]\n",
      "[131.29489406618364]\n",
      "[131.18426436418545]\n",
      "[131.44145849715204]\n",
      "[131.24612594939308]\n",
      "[113.15453723680724]\n",
      "[111.17976448961737]\n",
      "[110.7631712959157]\n",
      "[111.48945758475949]\n",
      "[112.89849385062415]\n",
      "[112.97824081668647]\n",
      "[112.84431315718021]\n",
      "[113.17008132797793]\n",
      "[113.54474827617095]\n",
      "[113.76006791780758]\n",
      "[114.24877993154483]\n",
      "[114.6082549542904]\n",
      "[114.55400018455086]\n",
      "[115.10095443476227]\n",
      "[115.2528868652556]\n",
      "[115.35110172906587]\n",
      "[115.55803950007218]\n",
      "[115.86308705010302]\n",
      "[115.9176340285426]\n",
      "[115.84715349914053]\n",
      "[137.30637463512417]\n",
      "[136.55409683075658]\n",
      "[138.0435944182882]\n",
      "[134.15639146757934]\n",
      "[131.49942299507305]\n",
      "[131.54963923776046]\n",
      "[131.2361897219075]\n",
      "[131.27899699570733]\n",
      "[130.65250817666376]\n",
      "[129.64747249452338]\n",
      "[128.91918143068057]\n",
      "[128.79083532651322]\n",
      "[128.2204683006676]\n",
      "[127.61499231900154]\n",
      "[127.4381282705946]\n",
      "[126.9769159387187]\n",
      "[126.7091610257082]\n",
      "[127.21308693299302]\n",
      "[127.18552099404734]\n",
      "[127.03321724784035]\n",
      "[152.3385987451896]\n",
      "[148.32216752561945]\n",
      "[149.9480631529163]\n",
      "[149.44821603356488]\n",
      "[150.05919713292886]\n",
      "[147.1778805664314]\n",
      "[145.82112154979632]\n",
      "[145.00816366209202]\n",
      "[144.3873025585641]\n",
      "[144.00493913795304]\n",
      "[142.93472701946652]\n",
      "[141.81763528921033]\n",
      "[141.28891846431074]\n",
      "[140.75400778425822]\n",
      "[140.32037776984163]\n",
      "[139.74692461993607]\n",
      "[139.36314519943602]\n",
      "[139.10693188984476]\n",
      "[138.70520159401698]\n",
      "[138.3685235522561]\n",
      "[140.42919780646997]\n",
      "[140.88593537997795]\n",
      "[141.76041515841797]\n",
      "[139.13709235415783]\n",
      "[138.0495169328782]\n",
      "[137.4747564018072]\n",
      "[137.54503733613393]\n",
      "[136.79433734318425]\n",
      "[135.72758997992628]\n",
      "[135.46518643370322]\n",
      "[134.73813752341565]\n",
      "[134.41962012891267]\n",
      "[133.93038242880493]\n",
      "[133.20653888293558]\n",
      "[133.24389400788863]\n",
      "[132.55492490446602]\n",
      "[132.64740468924026]\n",
      "[132.36053104033917]\n",
      "[131.9608778322869]\n",
      "[131.4709235552219]\n",
      "[132.3541088077286]\n",
      "[131.53194557232246]\n",
      "[130.89270824273316]\n",
      "[131.2036411693729]\n",
      "[132.7337286532712]\n",
      "[130.60729532832218]\n",
      "[130.14512519492604]\n",
      "[130.27995401064956]\n",
      "[130.2016688818264]\n",
      "[129.2530512315176]\n",
      "[129.23227339422212]\n",
      "[128.78511794510948]\n",
      "[129.07122132760537]\n",
      "[128.55040057567163]\n",
      "[128.46748008134793]\n",
      "[128.24516883182977]\n",
      "[127.91196233187003]\n",
      "[127.35614794415078]\n",
      "[127.07299286982767]\n",
      "[127.02069003228456]\n"
     ]
    }
   ],
   "source": [
    "for row in output_datalist:\n",
    "    print(row)\n",
    "\n",
    "with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
    "  writer = csv.writer(csvfile)\n",
    "  for row in output_datalist:\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtgCJU7FPeJL"
   },
   "source": [
    "# Report *(5%)*\n",
    "\n",
    "Report should be submitted as a pdf file **hw1_report.pdf**\n",
    "\n",
    "*   Briefly describe the difficulty you encountered\n",
    "*   Summarize your work and your reflections\n",
    "*   No more than one page\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlEE53_MPf4W"
   },
   "source": [
    "# Save the Code File\n",
    "Please save your code and submit it as an ipynb file! (**hw1.ipynb**)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
